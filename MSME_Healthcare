import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from xgboost import XGBRegressor
from sklearn.model_selection import LeaveOneOut, GridSearchCV, train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV
 
# Define the weight dictionaries and scoring criteria (unchanged)
metric_weights = {
    "Financial Metrics": 0.35,
    "Banking & Creditworthiness": 0.35,
    "Business Health & Risk Factors": 0.30
}
 
submetric_weights = {
    "Financial Metrics": {
                "Revenue Growth": 0.10,
                "EBITDA Margin": 0.05,
                "Receivables Turnover": 0.04,
                "ROE": 0.06,
                "ROCE": 0.06,
                "DSO": 0.04
            },
            "Banking & Creditworthiness": {
                "Quick Ratio": 0.08,
                "Current Ratio": 0.08,
                "D/E Ratio": 0.08,
                "Interest Coverage": 0.06,
                "DSR": 0.05
            },
            "Business Health & Risk Factors": {
                "Business Vintage": 0.06,
                "Customer Profile": 0.07,
                "Industry Outlook": 0.08,
                "Altman Z-Score": 0.09
            }
}
 
scoring_criteria = {
    "Financial Metrics": {
                "Revenue Growth": [(18, float('inf'), 5), (12, 18, 4), (8, 12, 3), (4, 8, 2), (float('-inf'), 4, 1)],
                "ROE": [(15, float('inf'), 5), (10, 15, 4), (6, 10, 3), (3, 6, 2), (float('-inf'), 3, 1)],
                "ROCE": [(15, float('inf'), 5), (10, 15, 4), (6, 10, 3), (3, 6, 2), (float('-inf'), 3, 1)],
                "EBITDA Margin": [(20, float('inf'), 5), (15, 20, 4), (10, 15, 3), (5, 10, 2), (float('-inf'), 5, 1)],
                "Receivables Turnover": [(7, float('inf'), 5), (5, 7, 4), (3, 5, 3), (2, 3, 2), (float('-inf'), 2, 1)],
                "DSO": [(float('-inf'), 45, 5), (45, 60, 4), (60, 75, 3), (75, 90, 2), (90, float('inf'), 1)],
            },
            "Banking & Creditworthiness": {
                "D/E Ratio": [(float('-inf'), 0.5, 5), (0.5, 1.0, 4), (1.0, 1.5, 3), (1.5, 2.0, 2), (2.0, float('inf'), 1)],
                "Quick Ratio": [(1.8, float('inf'), 5), (1.5, 1.8, 4), (1.2, 1.5, 3), (1.0, 1.2, 2), (float('-inf'), 1.0, 1)],
                "Current Ratio": [(2.0, float('inf'), 5), (1.5, 2.0, 4), (1.2, 1.5, 3), (1.0, 1.2, 2), (float('-inf'), 1.0, 1)],
                "Interest Coverage": [(5.0, float('inf'), 5), (3.0, 5.0, 4), (2.0, 3.0, 3), (1.5, 2.0, 2), (float('-inf'), 1.5, 1)],
                "DSR": [(3.5, float('inf'), 5), (2.5, 3.5, 4), (1.5, 2.5, 3), (1.0, 1.5, 2), (float('-inf'), 1.0, 1)],
            },
            "Business Health & Risk Factors": {
                "Business Vintage": [(10, float('inf'), 5), (7, 10, 4), (4, 7, 3), (2, 4, 2), (float('-inf'), 2, 1)],
                "Customer Profile": {"Large Clients": 5, "Mid-Sized Clients": 4, "Mixed Clients": 3, "Small Clients": 2, "Unstable Clients": 1},
                "Industry Outlook": {"Strong Growth": 5, "Moderate Growth": 4, "Stable": 3, "Declining": 2, "Severe Decline": 1},
                "Altman Z-Score": [(3.0, float('inf'), 5), (2.5, 3.0, 4), (1.8, 2.5, 3), (1.0, 1.8, 2), (float('-inf'), 1.0, 1)]
            }
}
 
# Mapping dictionaries for categorical variables
categorical_mappings = {
    "Customer Profile": {
        "Large Clients": 5,
        "Mid-Sized Clients": 4,
        "Mixed Clients": 3,
        "Small Clients": 2,
        "Unstable Clients": 1
    },
    "Industry Outlook": {
        "Strong Growth": 5,
        "Moderate Growth": 4,
        "Stable": 3,
        "Declining": 2,
        "Severe Decline": 1
    }
}
 
# Define category metrics mapping
category_metrics = {
    "Financial Metrics": [
        "revenue growth", "ebitda margin", "receivable turnover",
        "roe", "roce", "dso"
    ],
    "Banking & Creditworthiness": [
        "quick ratio", "current ratio", "d/e ratio",
        "interest coverage ratio", "dsr"
    ],
    "Business Health & Risk Factors": [
        "business vintage", "altman z score",
        "customer profile", "industry outlook"
    ]
}
 
# Create a mapping between column names and scoring criteria keys
column_to_criteria_key = {
    "revenue growth": "Revenue Growth",
    "ebitda margin": "EBITDA Margin",
    "receivable turnover": "Receivables Turnover",
    "roe": "ROE",
    "roce": "ROCE",
    "dso": "DSO",
    "quick ratio": "Quick Ratio",
    "current ratio": "Current Ratio",
    "d/e ratio": "D/E Ratio",
    "interest coverage ratio": "Interest Coverage",
    "dsr": "DSR",
    "business vintage": "Business Vintage",
    "altman z score": "Altman Z-Score",
    "customer profile": "Customer Profile",
    "industry outlook": "Industry Outlook"
}
 
def score_metric(category, metric, value):
    """Score a metric based on its value and criteria."""
    if pd.isna(value):
        return 3  # Default middle score for missing values
 
    # Map column name to criteria key
    criteria_key = column_to_criteria_key.get(metric, metric)
 
    # Handle categorical metrics
    if criteria_key in ["Customer Profile", "Industry Outlook"]:
        if isinstance(value, str):
            # For string values, get the score from the dictionary
            return scoring_criteria[category][criteria_key].get(value, 3)
        else:
            # If already numeric (mapped), return as is if in range 1-5
            return min(5, max(1, int(value)))
    # Handle numeric metrics
    else:
        try:
            numeric_value = float(value)
        except (ValueError, TypeError):
            return 3  # Default to middle score for invalid values
 
        for lower, upper, score in scoring_criteria[category][criteria_key]:
            if lower <= numeric_value < upper:
                return score
        return 1  # Default lowest score if no criteria match
 
def compute_ahp_score(row):
    """Compute the AHP score for a row of data."""
    total_score = 0
    total_applied_weight = 0
 
    for category, category_weight in metric_weights.items():
        category_score = 0
        category_applied_weight = 0
 
        for metric in category_metrics.get(category, []):
            if metric in row.index and not pd.isna(row[metric]):
                criteria_key = column_to_criteria_key.get(metric, metric)
                metric_weight = submetric_weights[category].get(criteria_key, 0)
 
                try:
                    metric_score = score_metric(category, metric, row[metric])
                    category_score += metric_score * metric_weight
                    category_applied_weight += metric_weight
                except Exception as e:
                    continue
 
        if category_applied_weight > 0:
            normalized_category_score = category_score / category_applied_weight
            total_score += normalized_category_score * category_weight
            total_applied_weight += category_weight
 
    return total_score / total_applied_weight if total_applied_weight > 0 else 3
 
def clean_extreme_outliers(df, columns, threshold=5):
    """Clean extreme outliers using IQR method with adjustable threshold."""
    df_cleaned = df.copy()
 
    for col in columns:
        if col in df.columns and df[col].dtype != 'object':
            q1 = df[col].quantile(0.25)
            q3 = df[col].quantile(0.75)
            iqr = q3 - q1
 
            lower_bound = q1 - threshold * iqr
            upper_bound = q3 + threshold * iqr
 
            # Replace outliers with NaN
            mask = (df[col] < lower_bound) | (df[col] > upper_bound)
            if mask.any():
                df_cleaned.loc[mask, col] = np.nan
 
    return df_cleaned
 
 
 
def remove_high_correlation(df, threshold=0.95):
    """Remove highly correlated features."""
    corr_matrix = df.corr().abs()
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
 
    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]
    return df.drop(to_drop, axis=1)
 
data_str = """Company Name\trevenue growth\tebitda margin\treceivable turnover\troe\troce\tdso\tquick ratio\tcurrent ratio\td/e ratio\tinterest coverage ratio\tdsr\tbusiness vintage\tAltman z score\tcustomer profile\tindustry outlook
A G S Health Pvt. Ltd.\t24.546545\t20.656557\t2.865209\t25.678047\t21.705296\t127.39034\t3.789285\t3.814864\t0.186115\t21.338216\t7.510668\t15\t2.685452305\tMid-Sized Clients\tStrong Growth
A H I V F & Infertility Research Centre Pvt. Ltd.\t-3.11042\t7.544141\t23.207547\t-2.644004\t-2.113208\t15.727642\t0.995708\t1.038627\t0.247619\t0.166667\t6.666667\t24\t0.706993042\tMid-Sized Clients\tStrong Growth
A N G Lifesciences India Ltd\t-39.033389\t7.30711\t1.77144\t-8.707416\t-5.101967\t206.047043\t0.60556\t1.117712\t0.770109\t0.16092\t0.172325\t19\t0.694473255\tMid-Sized Clients\tStrong Growth
Aakash Healthcare Pvt. Ltd.\t16.034444\t14.471243\t18.621021\t24.335451\t5.419355\t19.601503\t0.465524\t0.544063\t3.329953\t59.390244\t1.765706\t31\t1.007037371\tMid-Sized Clients\tStrong Growth
A V N Arogya Health Care Pvt. Ltd.\t32.46493\t13.615734\t82.583333\t17.882118\t13.606994\t4.419778\t0.373057\t1.082902\t0.253896\t9.136364\t6.842105\t17\t3.487682306\tMid-Sized Clients\tStrong Growth
A R K Diagnostics Bangalore Pvt. Ltd.\t-17.282479\t0.720461\t4.68942\t1.626016\t0.680272\t77.834789\t0.863071\t1.215768\t1.774194\t1.5\t0.035714\t13\t2.569450721\tMid-Sized Clients\tStrong Growth"""
 
 
 
def process_dataset():
    """Process financial data and build the model."""
    # Raw data string
 
 
    # 1. Load and preprocess the data
    rows = data_str.strip().split('\n')
    headers = [h.strip().lower() for h in rows[0].split('\t')]
 
    data = []
    for row in rows[1:]:
        values = row.split('\t')
        row_dict = {headers[i]: values[i] for i in range(min(len(headers), len(values)))}
        data.append(row_dict)
 
    df = pd.DataFrame(data)
 
    # 2. Clean and prepare data
    special_values = ['Not Available', 'Not Applicable', 'Missing', 'Not applicable']
    df = df.replace(special_values, np.nan)
 
    # Clean numeric columns
    for col in df.columns:
        if col not in ['company name', 'customer profile', 'industry outlook']:
            if df[col].dtype == 'object':
                df[col] = df[col].str.replace('%', '', regex=False)
                df[col] = df[col].str.replace('−', '-', regex=False)
                df[col] = df[col].str.replace(',', '', regex=False)
                df[col] = df[col].str.replace(' Years', '', regex=False)
                df[col] = df[col].str.replace(' Year', '', regex=False)
 
            df[col] = pd.to_numeric(df[col], errors='coerce')
 
    # Check for and handle extreme outliers - likely to be a data entry error
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    df = clean_extreme_outliers(df, numeric_cols, threshold=10)
 
    # Specifically check the revenue growth column for extreme values
    if 'revenue growth' in df.columns:
        # This handles the problematic 26,102.27 value (typo)
        # Set a reasonable cap based on domain knowledge
        reasonable_max = 100  # Assume max 100% growth
        df.loc[df['revenue growth'] > reasonable_max, 'revenue growth'] = np.nan
 
    # 3. Apply categorical mappings
    for col, mapping in categorical_mappings.items():
        col_lower = col.lower()
        if col_lower in df.columns:
            df[col_lower] = df[col_lower].map(lambda x: mapping.get(x, 3) if isinstance(x, str) else x)
 
    # 4. Identify features for modeling
    non_feature_cols = ['company', 'company name']
    feature_cols = [col for col in df.columns if col.lower() not in non_feature_cols and col != 'ahp_score']
 
    numeric_features = []
    for col in feature_cols:
        try:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            if df[col].notna().any():
                numeric_features.append(col)
        except:
            continue
 
    # 5. Calculate target AHP score
    df['ahp_score'] = df.apply(compute_ahp_score, axis=1)
 
    # 6. Create train and test sets
    X = df[feature_cols].copy()
    y = df['ahp_score'].copy()
 
    # Handle missing values using KNN imputation
    imputer = KNNImputer(n_neighbors=3)
    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)
 
    # Remove highly correlated features
    X_imputed = remove_high_correlation(X_imputed, threshold=0.95)
 
    # Split into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(
        X_imputed, y, test_size=0.3, random_state=42
    )
 
    # 7. Feature preprocessing pipeline
    numeric_transformer = Pipeline(steps=[
        ('scaler', RobustScaler()),
        ('selector', SelectKBest(f_regression, k=min(8, len(X_imputed.columns))))
    ])
 
    # 8. Model building and evaluation
    model = XGBRegressor(
        n_estimators=100,
        learning_rate=0.05,
        max_depth=3,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42
    )
 
    # Train the model
    model.fit(X_train, y_train)
 
    # Evaluate the model
    y_pred = model.predict(X_test)
 
    # Calculate metrics
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
 
    print(f"Model Performance:")
    print(f"RMSE: {rmse:.4f}")
    print(f"R2 Score: {r2:.4f}")
    print(f"MAE: {mae:.4f}")
 
    # 9. Feature importance analysis
    feature_importance = model.feature_importances_
    importance_df = pd.DataFrame({
        'Feature': X_imputed.columns,
        'Importance': feature_importance
    }).sort_values('Importance', ascending=False)
 
    print("\nFeature Importance:")
    print(importance_df)
 
    # 10. Alternative model comparison
    # Try RandomForest as an alternative model
    rf_model = RandomForestRegressor(
        n_estimators=100,
        max_depth=5,
        random_state=42
    )
 
    rf_model.fit(X_train, y_train)
    rf_pred = rf_model.predict(X_test)
 
    rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))
    rf_r2 = r2_score(y_test, rf_pred)
 
    print("\nRandom Forest Performance:")
    print(f"RMSE: {rf_rmse:.4f}")
    print(f"R2 Score: {rf_r2:.4f}")
 
    # 11. Visualization of predicted vs actual values
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred, alpha=0.7)
    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
    plt.xlabel('Actual AHP Score')
    plt.ylabel('Predicted AHP Score')
    plt.title('XGBoost: Actual vs Predicted AHP Scores')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
 
    # 12. Hyperparameter tuning with cross-validation
    param_grid = {
        'n_estimators': [50, 100, 200],
        'learning_rate': [0.01, 0.05, 0.1],
        'max_depth': [2, 3, 4, 5],
        'subsample': [0.7, 0.8, 0.9],
        'colsample_bytree': [0.7, 0.8, 0.9]
    }
 
    # Fix the RandomizedSearchCV implementation
    try:
        random_search = RandomizedSearchCV(
            estimator=XGBRegressor(random_state=42),
            param_distributions=param_grid,
            n_iter=10,  # Reduced from 20 to speed up execution
            scoring='neg_mean_squared_error',
            cv=3,  # Reduced from 5 to speed up execution
            verbose=1,
            random_state=42,
            n_jobs=1  # Changed from -1 to avoid potential parallel processing issues
        )
 
        random_search.fit(X_imputed, y)
 
        print("\nBest Hyperparameters:")
        print(random_search.best_params_)
        print(f"Best Cross-Validation Score (RMSE): {np.sqrt(-random_search.best_score_):.4f}")
 
        # 13. Evaluate best model
        best_model = random_search.best_estimator_
        best_pred = best_model.predict(X_test)
        best_rmse = np.sqrt(mean_squared_error(y_test, best_pred))
        best_r2 = r2_score(y_test, best_pred)
 
        print("\nTuned Model Performance:")
        print(f"RMSE: {best_rmse:.4f}")
        print(f"R2 Score: {best_r2:.4f}")
    except Exception as e:
        print(f"\nError during hyperparameter tuning: {str(e)}")
        print("Using the base XGBoost model instead.")
        best_model = model
        best_rmse = rmse
        best_r2 = r2
 
    # 14. Save the best model
    try:
        import joblib
        joblib.dump(best_model, 'healthcare_prediction_model.pkl')
        print("\nModel saved as 'healthcare_prediction_model.pkl'")
    except Exception as e:
        print(f"\nError saving model: {str(e)}")
 
    # 15. Function to predict AHP score for new companies
    def predict_ahp_score(new_data):
        """
        Predict AHP score for new company data.
 
        Parameters:
        new_data (dict): Dictionary with company metrics as keys and values
 
        Returns:
        float: Predicted AHP score
        """
        # Convert to DataFrame
        new_df = pd.DataFrame([new_data])
 
        # Apply same preprocessing as training data
        for col, mapping in categorical_mappings.items():
            col_lower = col.lower()
            if col_lower in new_df.columns:
                new_df[col_lower] = new_df[col_lower].map(lambda x: mapping.get(x, 3) if isinstance(x, str) else x)
 
        # Create a DataFrame with all original features for imputation
        all_features_df = pd.DataFrame(columns=feature_cols)
        for col in feature_cols:
            if col in new_data:
                all_features_df[col] = [new_data[col]]
            else:
                all_features_df[col] = [np.nan]
       
        # Apply imputation to all features
        all_features_imputed = pd.DataFrame(
            imputer.transform(all_features_df),
            columns=feature_cols
        )
       
        # Select only the filtered features used in the model
        model_input = all_features_imputed[X_imputed.columns]
 
        # Make prediction
        prediction = best_model.predict(model_input)[0]
 
        return prediction
 
    # Store the feature columns used for prediction
    feature_cols = [col for col in df.columns if col.lower() not in non_feature_cols and col != 'ahp_score']
 
    return best_model, imputer, feature_cols, X_imputed.columns, predict_ahp_score
if __name__ == "__main__":
    model, imputer, all_features, model_features, predict_function = process_dataset()
 
    # Get the original dataset
    rows = data_str.strip().split('\n')
    headers = [h.strip().lower() for h in rows[0].split('\t')]
 
    data = []
    for row in rows[1:]:
        values = row.split('\t')
        row_dict = {headers[i]: values[i] for i in range(min(len(headers), len(values)))}
        data.append(row_dict)
 
    df = pd.DataFrame(data)
 
    # Clean and preprocess the same way as in process_dataset
    special_values = ['Not Available', 'Not Applicable', 'Missing', 'Not applicable']
    df = df.replace(special_values, np.nan)
 
    # Clean numeric columns
    for col in df.columns:
        if col not in ['company name', 'customer profile', 'industry outlook']:
            if df[col].dtype == 'object':
                df[col] = df[col].str.replace('%', '', regex=False)
                df[col] = df[col].str.replace('−', '-', regex=False)
                df[col] = df[col].str.replace(',', '', regex=False)
                df[col] = df[col].str.replace(' Years', '', regex=False)
                df[col] = df[col].str.replace(' Year', '', regex=False)
 
            df[col] = pd.to_numeric(df[col], errors='coerce')
 
    # Apply categorical mappings
    for col, mapping in categorical_mappings.items():
        col_lower = col.lower()
        if col_lower in df.columns:
            df[col_lower] = df[col_lower].map(lambda x: mapping.get(x, 3) if isinstance(x, str) else x)
 
    # Calculate actual AHP scores
    df['actual_ahp_score'] = df.apply(compute_ahp_score, axis=1)
 
    # Print model features to debug
    print("\nAll features used for imputation:")
    print(all_features)
   
    print("\nModel features used for prediction:")
    print(model_features)
   
    print("\nColumns in the test dataframe:")
    print(df.columns.tolist())
 
    # Predict AHP scores for all companies
    results = []
    for idx, row in df.iterrows():
        company_name = row['company name']
       
        # Create company data dictionary with all available features
        # Exclude 'actual_ahp_score' and 'company name' from the data
        company_data = {}
        for col in df.columns:
            if col != 'actual_ahp_score' and col != 'company name':
                company_data[col] = row[col]
 
        try:
            predicted_score = predict_function(company_data)
            actual_score = row['actual_ahp_score']
            results.append({
                'Company': company_name,
                'Predicted Score': predicted_score,
                'Actual Score': actual_score,
                'Difference': abs(predicted_score - actual_score)
            })
        except Exception as e:
            print(f"Error predicting for {company_name}: {str(e)}")
            # Print the keys in company_data for debugging
            print(f"Company data keys: {list(company_data.keys())}")
            continue
 
    # Display results
    if results:
        results_df = pd.DataFrame(results)
        print("\nPredictions for all companies in dataset:")
        print(results_df)
 
        # Calculate overall metrics
        rmse = np.sqrt(mean_squared_error(results_df['Actual Score'], results_df['Predicted Score']))
        r2 = r2_score(results_df['Actual Score'], results_df['Predicted Score'])
        mae = mean_absolute_error(results_df['Actual Score'], results_df['Predicted Score'])
 
        print(f"\nOverall Performance on Original Dataset:")
        print(f"RMSE: {rmse:.4f}")
        print(f"R2 Score: {r2:.4f}")
        print(f"MAE: {mae:.4f}")
    else:
        print("\nNo valid predictions were made.")
           
